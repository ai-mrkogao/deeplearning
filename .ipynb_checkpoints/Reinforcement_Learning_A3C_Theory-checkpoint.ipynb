{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of MDPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MDP is a collection of 5 things  \n",
    "\n",
    "- states\n",
    "- actions\n",
    "- rewards\n",
    "- state trasition probabilities\n",
    "- discount factor(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Property\n",
    "\n",
    "$p[s(t+1),r(t+1)|s(t),a(t),...,s(1),a(1)] $ = $p[s(t+1),r(t+1)|s(t),a(t)] $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discount Factor\n",
    "\n",
    "$G(t) = \\sum_{\\tau = 0}^{\\infty}\\gamma^{\\tau}R(t+\\tau+1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State value and state action value\n",
    "\n",
    "$V_{\\pi}(s) = E_{\\pi}[G(t)|S_{t}=s]$  \n",
    "$Q_{\\pi}(s,a) = E_{\\pi}[G(t)|S_{t}=s,A_{t}=a]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\pi(s) = argmax_{a}{(Q(s,a))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V_{\\pi}(s) = \\sum_{a}^{}\\pi(a|s)\\sum_{s'}^{}\\sum_{r}^{}p(s',r|s,a)(r+\\gamma V_{\\pi}(s'))$  \n",
    "\n",
    "![](https://lilianweng.github.io/lil-log/assets/images/TD_MC_DP_backups.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Policy Evaluation\n",
    "- prediction problem: given a policy , find the value function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Iteration\n",
    "\n",
    "```python\n",
    "while not converged:\n",
    "    step1) policy evaluation of current policy\n",
    "    step2) policy improvement(take the argmax Q(s,a))\n",
    "```    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration\n",
    "\n",
    "- Q-learning\n",
    "\n",
    "$V_{k+1}(s) = max_{a}\\sum_{s'}^{}\\sum_{r}^{}p(s',r|s,a)(r+\\gamma V_{\\pi}(s'))$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Programming Summary\n",
    "\n",
    "- it is not practical\n",
    "- state space may be very large\n",
    "- doesn't learn from experience\n",
    "- MC and TD learning, no model of the environment needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unlike DP, MC is all about learning from experience\n",
    "\n",
    "$V(s) = E[G(t)|S(t)=s]\\approx \\frac{1}{N}\\sum_{N}^{i=1}G_{i,s}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Control\n",
    "\n",
    "1. Initailize random policy\n",
    "2. while not converged:\n",
    "    - a. play an episode,calculate retruns for each state\n",
    "    - b. do policy improvements based on current Q(s,a)take argmax\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MC: sample returns based on an episode\n",
    "- TD: estimate returns based on current value function estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TD(0)  \n",
    "\n",
    "$V(S_{t}) = V(S_{t})+\\alpha[r+\\gamma V(S_{t+1})-V(S_{t})]$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD Control\n",
    "\n",
    "#### SARSA\n",
    "\n",
    "$Q(s,a) \\leftarrow Q(s,a) + \\alpha [r+\\gamma Q(s',a') - Q(s,a)]$  \n",
    "$a' = argmax_{a}[Q(s',a)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Learning\n",
    "- off policy \n",
    "\n",
    "$Q(s,a) \\leftarrow Q(s,a) + \\alpha [r+\\gamma *max_{a'}Q(s',a') - Q(s,a)]$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CartPole Q-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Model:\n",
    "  def __init__(self, env, feature_transformer):\n",
    "    self.env = env\n",
    "    self.feature_transformer = feature_transformer\n",
    "\n",
    "    num_states = 10**env.observation_space.shape[0]\n",
    "    num_actions = env.action_space.n\n",
    "    self.Q = np.random.uniform(low=-1, high=1, size=(num_states, num_actions))\n",
    "\n",
    "  def predict(self, s):\n",
    "    x = self.feature_transformer.transform(s)\n",
    "    return self.Q[x]\n",
    "\n",
    "  def update(self, s, a, G):\n",
    "    x = self.feature_transformer.transform(s)\n",
    "    self.Q[x,a] += 1e-2*(G - self.Q[x,a])\n",
    "\n",
    "  def sample_action(self, s, eps):\n",
    "    if np.random.random() < eps:\n",
    "      return self.env.action_space.sample()\n",
    "    else:\n",
    "      p = self.predict(s)\n",
    "      return np.argmax(p)\n",
    "\n",
    "def play_one(model, eps, gamma):\n",
    "  observation = env.reset()\n",
    "  done = False\n",
    "  totalreward = 0\n",
    "  iters = 0\n",
    "  while not done and iters < 10000:\n",
    "    action = model.sample_action(observation, eps)\n",
    "    prev_observation = observation\n",
    "    observation, reward, done, info = env.step(action)\n",
    "\n",
    "    totalreward += reward\n",
    "\n",
    "    if done and iters < 199:\n",
    "      reward = -300\n",
    "\n",
    "    # update the model\n",
    "    G = reward + gamma*np.max(model.predict(observation))\n",
    "    model.update(prev_observation, action, G)\n",
    "\n",
    "    iters += 1\n",
    "\n",
    "  return totalreward\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "env.observation_space.shape[0] 4\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "episode: 0 total reward: 10.0 eps: 1.0\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4465\n",
      "predict x 5445\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5444\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5544\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5732\n",
      "predict x 5732\n",
      "predict x 5623\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5454\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5454\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4267\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4654\n",
      "predict x 4654\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4545\n",
      "predict x 4545\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5732\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4644\n",
      "predict x 4644\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4267\n",
      "predict x 4267\n",
      "predict x 4277\n",
      "predict x 4277\n",
      "predict x 4277\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4277\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4545\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4466\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4555\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5743\n",
      "predict x 5743\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5733\n",
      "predict x 5722\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4654\n",
      "predict x 4654\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5633\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5633\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4444\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 5545\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5545\n",
      "predict x 5545\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4554\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 4555\n",
      "predict x 4555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 4555\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5623\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 4554\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4366\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 4555\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5555\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5732\n",
      "predict x 4544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 4444\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 4555\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5732\n",
      "predict x 4454\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4466\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5623\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4356\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5732\n",
      "predict x 5454\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5444\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 5444\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5444\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5555\n",
      "predict x 4444\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4654\n",
      "predict x 4654\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5545\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4654\n",
      "predict x 4654\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5644\n",
      "predict x 5633\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5444\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4444\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4346\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict x 4356\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4355\n",
      "predict x 4355\n",
      "predict x 4455\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5534\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5732\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5444\n",
      "predict x 5444\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5545\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5534\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5633\n",
      "predict x 5733\n",
      "predict x 5733\n",
      "predict x 5633\n",
      "predict x 5545\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5545\n",
      "predict x 5545\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5554\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 5555\n",
      "predict x 5455\n",
      "predict x 5455\n",
      "predict x 5555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 5455\n",
      "predict x 5554\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5445\n",
      "predict x 5445\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5544\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 5643\n",
      "predict x 5644\n",
      "predict x 5644\n",
      "predict x 5643\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4554\n",
      "predict x 4653\n",
      "predict x 4653\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4544\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4445\n",
      "predict x 4345\n",
      "predict x 4345\n",
      "predict x 4346\n",
      "predict x 4555\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4356\n",
      "predict x 4356\n",
      "predict x 4455\n",
      "predict x 4455\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "predict x 4465\n",
      "predict x 4366\n",
      "predict x 4366\n",
      "predict x 4465\n",
      "avg reward for last 100 episodes: 9.99\n",
      "total steps: 999.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://deeplearningcourses.com/c/deep-reinforcement-learning-in-python\n",
    "# https://www.udemy.com/deep-reinforcement-learning-in-python\n",
    "from __future__ import print_function, division\n",
    "from builtins import range\n",
    "# Note: you may need to update your version of future\n",
    "#       if builtins is not defined\n",
    "# sudo pip install -U future\n",
    "\n",
    "import gym\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import wrappers\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# turns list of integers into an int\n",
    "# Ex.\n",
    "# build_state([1,2,3,4,5]) -> 12345\n",
    "def build_state(features):\n",
    "  return int(\"\".join(map(lambda feature: str(int(feature)), features)))\n",
    "\n",
    "def to_bin(value, bins):\n",
    "  return np.digitize(x=[value], bins=bins)[0]\n",
    "\n",
    "\n",
    "class FeatureTransformer:\n",
    "  def __init__(self):\n",
    "    # Note: to make this better you could look at how often each bin was\n",
    "    # actually used while running the script.\n",
    "    # It's not clear from the high/low values nor sample() what values\n",
    "    # we really expect to get.\n",
    "    self.cart_position_bins = np.linspace(-2.4, 2.4, 9)\n",
    "    self.cart_velocity_bins = np.linspace(-2, 2, 9) # (-inf, inf) (I did not check that these were good values)\n",
    "    self.pole_angle_bins = np.linspace(-0.4, 0.4, 9)\n",
    "    self.pole_velocity_bins = np.linspace(-3.5, 3.5, 9) # (-inf, inf) (I did not check that these were good values)\n",
    "\n",
    "  def transform(self, observation):\n",
    "    # returns an int\n",
    "    cart_pos, cart_vel, pole_angle, pole_vel = observation\n",
    "    return build_state([\n",
    "      to_bin(cart_pos, self.cart_position_bins),\n",
    "      to_bin(cart_vel, self.cart_velocity_bins),\n",
    "      to_bin(pole_angle, self.pole_angle_bins),\n",
    "      to_bin(pole_vel, self.pole_velocity_bins),\n",
    "    ])\n",
    "\n",
    "\n",
    "class Model:\n",
    "  def __init__(self, env, feature_transformer):\n",
    "    self.env = env\n",
    "    self.feature_transformer = feature_transformer\n",
    "    print(\"env.observation_space.shape[0] {}\".format(env.observation_space.shape[0]))\n",
    "    num_states = 10**env.observation_space.shape[0]\n",
    "    num_actions = env.action_space.n\n",
    "    self.Q = np.random.uniform(low=-1, high=1, size=(num_states, num_actions))\n",
    "\n",
    "  def predict(self, s):\n",
    "    x = self.feature_transformer.transform(s)\n",
    "    print(\"predict x {}\".format(x))\n",
    "    return self.Q[x]\n",
    "\n",
    "  def update(self, s, a, G):\n",
    "    x = self.feature_transformer.transform(s)\n",
    "    self.Q[x,a] += 1e-2*(G - self.Q[x,a])\n",
    "\n",
    "  def sample_action(self, s, eps):\n",
    "    if np.random.random() < eps:\n",
    "      return self.env.action_space.sample()\n",
    "    else:\n",
    "      p = self.predict(s)\n",
    "      return np.argmax(p)\n",
    "\n",
    "\n",
    "def play_one(model, eps, gamma):\n",
    "  observation = env.reset()\n",
    "  done = False\n",
    "  totalreward = 0\n",
    "  iters = 0\n",
    "  while not done and iters < 10:#10000:\n",
    "    action = model.sample_action(observation, eps)\n",
    "    prev_observation = observation\n",
    "    observation, reward, done, info = env.step(action)\n",
    "\n",
    "    totalreward += reward\n",
    "\n",
    "    if done and iters < 199:\n",
    "      reward = -300\n",
    "\n",
    "    # update the model\n",
    "    G = reward + gamma*np.max(model.predict(observation))\n",
    "    model.update(prev_observation, action, G)\n",
    "\n",
    "    iters += 1\n",
    "\n",
    "  return totalreward\n",
    "\n",
    "\n",
    "def plot_running_avg(totalrewards):\n",
    "  N = len(totalrewards)\n",
    "  running_avg = np.empty(N)\n",
    "  for t in range(N):\n",
    "    running_avg[t] = totalrewards[max(0, t-100):(t+1)].mean()\n",
    "  plt.plot(running_avg)\n",
    "  plt.title(\"Running Average\")\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  env = gym.make('CartPole-v0')\n",
    "  ft = FeatureTransformer()\n",
    "  model = Model(env, ft)\n",
    "  gamma = 0.9\n",
    "\n",
    "  if 'monitor' in sys.argv:\n",
    "    filename = os.path.basename(__file__).split('.')[0]\n",
    "    monitor_dir = './' + filename + '_' + str(datetime.now())\n",
    "    env = wrappers.Monitor(env, monitor_dir)\n",
    "\n",
    "  N = 100#10000\n",
    "  totalrewards = np.empty(N)\n",
    "  for n in range(N):\n",
    "    eps = 1.0/np.sqrt(n+1)\n",
    "    totalreward = play_one(model, eps, gamma)\n",
    "    totalrewards[n] = totalreward\n",
    "    if n % 100 == 0:\n",
    "      print(\"episode:\", n, \"total reward:\", totalreward, \"eps:\", eps)\n",
    "  print(\"avg reward for last 100 episodes:\", totalrewards[-100:].mean())\n",
    "  print(\"total steps:\", totalrewards.sum())\n",
    "\n",
    "  plt.plot(totalrewards)\n",
    "  plt.title(\"Rewards\")\n",
    "  plt.show()\n",
    "\n",
    "  plot_running_avg(totalrewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.62752321,  0.20833587],\n",
       "       [-0.31446745,  0.24937245],\n",
       "       [ 0.82065179,  0.40101559],\n",
       "       ...,\n",
       "       [ 0.96829641,  0.41341637],\n",
       "       [ 0.24372011, -0.94968371],\n",
       "       [ 0.31083868, -0.71684932]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.Q.shape\n",
    "model.Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-step methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Value Function  \n",
    "$V_{\\pi}(s) = \\sum_{a}^{}\\pi(a|s)\\sum_{s'}^{}\\sum_{r}^{}p(s',r|s,a)(r+\\gamma V_{\\pi}(s'))$   \n",
    "$V(s) = E[G(t)|S(t)=s]\\approx \\frac{1}{N}\\sum_{N}^{i=1}G_{i,s}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TD(0)\n",
    "\n",
    "$G_{s} \\approx r+\\gamma V(s')$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N-Step \n",
    "\n",
    "$G_{t}^{n} = R(t+1)+\\gamma R(t+2)+...+\\gamma^{n -1} R(t+n)+\\gamma^{n}V(s(t+n))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\text{Tabular}$ : $V(s(t)) = V(s(t)) +\\alpha (G^{n}(t)-V(s(t))$  \n",
    "$\\text{Function Approx}$ : $\\theta = \\theta+\\alpha (G^{n}(t)-V(s(t))\\frac{\\partial V(s(t))}{\\partial \\theta}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Control\n",
    "\n",
    "'use Q instead of V'  \n",
    "\n",
    "$G^{n}(t) = R(t+1)+ \\gamma R(t+2) + ... + \\gamma^{n-1}R(t+n) +\\gamma^{n}Q(s_{t+n},a_{t+n})$  \n",
    "$\\theta = \\theta+\\alpha (G^{n}(t)-Q(s_{t},s_{a}))\\frac{\\partial Q(s_{t},s_{a})}{\\partial \\theta}$  \n",
    "$a_{t} = argmax_{a}Q(s_{t},a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-step code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "if __name__ == '__main__':\n",
    "  env = gym.make('MountainCar-v0')\n",
    "  ft = FeatureTransformer(env)\n",
    "  model = Model(env, ft, \"constant\")\n",
    "  gamma = 0.99\n",
    "\n",
    "  N = 300\n",
    "  totalrewards = np.empty(N)\n",
    "  costs = np.empty(N)\n",
    "  for n in range(N):\n",
    "    # eps = 1.0/(0.1*n+1)\n",
    "    eps = 0.1*(0.97**n)\n",
    "    totalreward = play_one(model, eps, gamma)\n",
    "    totalrewards[n] = totalreward\n",
    "    print(\"episode:\", n, \"total reward:\", totalreward)\n",
    "  print(\"avg reward for last 100 episodes:\", totalrewards[-100:].mean())\n",
    "  print(\"total steps:\", -totalrewards.sum())\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def play_one(model, eps, gamma, n=5):\n",
    "  observation = env.reset()\n",
    "  done = False\n",
    "  totalreward = 0\n",
    "  rewards = []\n",
    "  states = []\n",
    "  actions = []\n",
    "  iters = 0\n",
    "  # array of [gamma^0, gamma^1, ..., gamma^(n-1)]\n",
    "  multiplier = np.array([gamma]*n)**np.arange(n)\n",
    "  # while not done and iters < 200:\n",
    "  while not done and iters < 10000:\n",
    "    # in earlier versions of gym, episode doesn't automatically\n",
    "    # end when you hit 200 steps\n",
    "    action = model.sample_action(observation, eps)\n",
    "\n",
    "    states.append(observation)\n",
    "    actions.append(action)\n",
    "\n",
    "    prev_observation = observation\n",
    "    observation, reward, done, info = env.step(action)\n",
    "\n",
    "    rewards.append(reward)\n",
    "\n",
    "    # update the model\n",
    "    if len(rewards) >= n:\n",
    "      # return_up_to_prediction = calculate_return_before_prediction(rewards, gamma)\n",
    "      return_up_to_prediction = multiplier.dot(rewards[-n:])\n",
    "      G = return_up_to_prediction + (gamma**n)*np.max(model.predict(observation)[0])\n",
    "      model.update(states[-n], actions[-n], G)\n",
    "\n",
    "    # if len(rewards) > n:\n",
    "    #   rewards.pop(0)\n",
    "    #   states.pop(0)\n",
    "    #   actions.pop(0)\n",
    "    # assert(len(rewards) <= n)\n",
    "\n",
    "    totalreward += reward\n",
    "    iters += 1\n",
    "\n",
    "  # empty the cache\n",
    "  if n == 1:\n",
    "    rewards = []\n",
    "    states = []\n",
    "    actions = []\n",
    "  else:\n",
    "    rewards = rewards[-n+1:]\n",
    "    states = states[-n+1:]\n",
    "    actions = actions[-n+1:]\n",
    "  # unfortunately, new version of gym cuts you off at 200 steps\n",
    "  # even if you haven't reached the goal.\n",
    "  # it's not good to do this UNLESS you've reached the goal.\n",
    "  # we are \"really done\" if position >= 0.5\n",
    "  if observation[0] >= 0.5:\n",
    "    # we actually made it to the goal\n",
    "    # print(\"made it!\")\n",
    "    while len(rewards) > 0:\n",
    "      G = multiplier[:len(rewards)].dot(rewards)\n",
    "      model.update(states[0], actions[0], G)\n",
    "      rewards.pop(0)\n",
    "      states.pop(0)\n",
    "      actions.pop(0)\n",
    "  else:\n",
    "    # we did not make it to the goal\n",
    "    # print(\"didn't make it...\")\n",
    "    while len(rewards) > 0:\n",
    "      guess_rewards = rewards + [-1]*(n - len(rewards))\n",
    "      G = multiplier.dot(guess_rewards)\n",
    "      model.update(states[0], actions[0], G)\n",
    "      rewards.pop(0)\n",
    "      states.pop(0)\n",
    "      actions.pop(0)\n",
    "\n",
    "  return totalreward\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class SGDRegressor:\n",
    "  def __init__(self, **kwargs):\n",
    "    self.w = None\n",
    "    self.lr = 1e-2\n",
    "  'Update weight' \n",
    "  def partial_fit(self, X, Y):\n",
    "    if self.w is None:\n",
    "      D = X.shape[1]\n",
    "      self.w = np.random.randn(D) / np.sqrt(D)\n",
    "    self.w += self.lr*(Y - X.dot(self.w)).dot(X)\n",
    "\n",
    "  def predict(self, X):\n",
    "    return X.dot(self.w)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generalized N-step method\n",
    "- $TD(\\lambda)$ allow us a more elegant method to trade-off between TD(0) and MC\n",
    "- $\\lambda$ = 0 gives us TD(0), $\\lambda$ =1 gives us MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $TD(\\lambda)$ \n",
    "\n",
    "$\\lambda_{1}G^{(1)}(t)$ + $\\lambda_{2}G^{(2)}(t)$ + ...+ $\\lambda_{n}G^{(n)}(t)$, $\\sum_{i=1}^{n}\\lambda_{i}=1$\n",
    "\n",
    "$G^{n}(t) = R(t+1)+ \\gamma R(t+2) + ... + \\gamma^{n-1}R(t+n) +\\gamma^{n}Q(s_{t+n},a_{t+n})$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$G_{\\lambda}(t) = (1-\\lambda)\\sum_{n=1}^{\\infty}\\lambda^{n-1}G^{n}(t)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we assume our episode will end at some point(time step T)\n",
    "\n",
    "$G_{\\lambda}(t) = (1-\\lambda)\\sum_{n=1}^{T-t-1}\\lambda^{n-1}G^{n}(t)$ + $(1-\\lambda)\\sum_{n=T-t}^{\\infty}\\lambda^{n-1}G(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- manipulate 2nd term to simplify the sum\n",
    "\n",
    "$G_{\\lambda}(t) = (1-\\lambda)\\sum_{n=1}^{T-t-1}\\lambda^{n-1}G^{n}(t)$ + $(1-\\lambda)G(t)\\lambda^{-1}\\sum_{n=T-t}^{\\infty}\\lambda^{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$G_{\\lambda}(t) = (1-\\lambda)\\sum_{n=1}^{T-t-1}\\lambda^{n-1}G^{n}(t)$ + $\\lambda^{T-t-1}G(t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The algorithm we're going to learn is an approximation to calculating the true $\\lambda$ return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TD(0)\n",
    "\n",
    "$\\text{TD target}: R_{t+1}+\\gamma V(s_{t+1})$  \n",
    "$\\text{prediction}: V(s_{t})$  \n",
    "$\\text{difference,TD error}: \\delta_{t} =  R_{t+1}+\\gamma V(s_{t+1}) - V(s_{t})$  \n",
    "$\\text{parameter update}:\\theta_{t+1} = \\theta_{t}+ \\alpha \\delta_{t} \\nabla_{\\theta}V(s_{t}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eligibility Trace\n",
    "    - Eligibility trace/ vector keeps track of old gradients,\n",
    "\n",
    "$e_{0} = 0$, $e_{t} = \\nabla_{\\theta}V(s_{t})+\\gamma \\lambda e_{t-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- redefine \n",
    "\n",
    "$\\text{parameter update}:\\theta_{t+1} = \\theta_{t}+ \\alpha \\delta_{t} e_{t} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- recall the momemtum works\n",
    "\n",
    "$v_{0} = 0$, $v_{t} = \\nabla_{\\theta}J+\\mu v_{t-1}$  \n",
    "$\\theta_{t+1} = \\theta_{t}+ \\alpha v_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Final thoughts\n",
    "\n",
    "    - N-step method and true $\\lambda$ return requires for future rewards\n",
    "        - forward view\n",
    "    - TD($\\lambda$) , we update the current param based on past errors\n",
    "        - backward view\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TD lambda code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "import gym\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import wrappers\n",
    "from datetime import datetime\n",
    "\n",
    "# code we already wrote\n",
    "from q_learning import plot_cost_to_go, FeatureTransformer, plot_running_avg\n",
    "\n",
    "\n",
    "class BaseModel:\n",
    "  def __init__(self, D):\n",
    "    self.w = np.random.randn(D) / np.sqrt(D)\n",
    "\n",
    "  def partial_fit(self, input_, target, eligibility, lr=1e-2):\n",
    "    self.w += lr*(target - input_.dot(self.w))*eligibility\n",
    "\n",
    "  def predict(self, X):\n",
    "    X = np.array(X)\n",
    "    return X.dot(self.w)\n",
    "\n",
    "# Holds one BaseModel for each action\n",
    "class Model:\n",
    "  def __init__(self, env, feature_transformer):\n",
    "    self.env = env\n",
    "    self.models = []\n",
    "    self.feature_transformer = feature_transformer\n",
    "\n",
    "    D = feature_transformer.dimensions\n",
    "    self.eligibilities = np.zeros((env.action_space.n, D))\n",
    "    for i in range(env.action_space.n):\n",
    "      model = BaseModel(D)\n",
    "      self.models.append(model)\n",
    "\n",
    "  def predict(self, s):\n",
    "    X = self.feature_transformer.transform([s])\n",
    "    assert(len(X.shape) == 2)\n",
    "    result = np.stack([m.predict(X) for m in self.models]).T\n",
    "    assert(len(result.shape) == 2)\n",
    "    return result\n",
    "\n",
    "  def update(self, s, a, G, gamma, lambda_):\n",
    "    X = self.feature_transformer.transform([s])\n",
    "    assert(len(X.shape) == 2)\n",
    "    self.eligibilities *= gamma*lambda_\n",
    "    'X[0] feature vector : gradient '\n",
    "    self.eligibilities[a] += X[0]\n",
    "    self.models[a].partial_fit(X[0], G, self.eligibilities[a])\n",
    "\n",
    "  def sample_action(self, s, eps):\n",
    "    if np.random.random() < eps:\n",
    "      return self.env.action_space.sample()\n",
    "    else:\n",
    "      return np.argmax(self.predict(s))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# returns a list of states_and_rewards, and the total reward\n",
    "def play_one(model, env, eps, gamma, lambda_):\n",
    "  observation = env.reset()\n",
    "  done = False\n",
    "  totalreward = 0\n",
    "  iters = 0\n",
    "  # while not done and iters < 200:\n",
    "  while not done and iters < 10000:\n",
    "    action = model.sample_action(observation, eps)\n",
    "    prev_observation = observation\n",
    "    observation, reward, done, info = env.step(action)\n",
    "\n",
    "    # update the model\n",
    "    next = model.predict(observation)\n",
    "    assert(next.shape == (1, env.action_space.n))\n",
    "    G = reward + gamma*np.max(next[0])\n",
    "    model.update(prev_observation, action, G, gamma, lambda_)\n",
    "\n",
    "    totalreward += reward\n",
    "    iters += 1\n",
    "\n",
    "  return totalreward\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  env = gym.make('MountainCar-v0')\n",
    "  ft = FeatureTransformer(env)\n",
    "  model = Model(env, ft)\n",
    "  gamma = 0.9999\n",
    "  lambda_ = 0.7\n",
    "\n",
    "\n",
    "  N = 300\n",
    "  totalrewards = np.empty(N)\n",
    "  costs = np.empty(N)\n",
    "  for n in range(N):\n",
    "    # eps = 1.0/(0.1*n+1)\n",
    "    eps = 0.1*(0.97**n)\n",
    "    # eps = 0.5/np.sqrt(n+1)\n",
    "    totalreward = play_one(model, env, eps, gamma, lambda_)\n",
    "    totalrewards[n] = totalreward\n",
    "    print(\"episode:\", n, \"total reward:\", totalreward)\n",
    "  print(\"avg reward for last 100 episodes:\", totalrewards[-100:].mean())\n",
    "  print(\"total steps:\", -totalrewards.sum())\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF network + SGD regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://chrisjmccormick.files.wordpress.com/2013/08/architecture_simple2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### policy gradient methods\n",
    "\n",
    "- softmax to turn the scores into probabilities that sum to 1  \n",
    "\n",
    "$\\pi(a_{j}|s) = \\frac{exp(score_{j})}{\\sum_{j'}^{}exp(score_{j'})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- parameterize the policy and the value function\n",
    "\n",
    "$\\text{Policy}$: $\\pi(a|s,\\theta_{p})$ = $f(s;\\theta_{p})$  \n",
    "$\\text{Value function approximation}$: $\\hat{V}_{\\pi}(s)$ = $f(s;\\theta_{v})$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Gradient Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla \\eta(\\theta_{p})$ = E[$\\sum_{a}^{}Q_{\\pi}(s,a)\\nabla_{\\theta_{p}}\\pi(a|s,\\theta_{p})$]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla \\eta(\\theta_{p})$ = E[$G\\nabla_{\\theta_{p}}log\\pi(a|s,\\theta_{p})$]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- this is gradient ascent\n",
    "- we want to maximize the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batches  \n",
    "\n",
    "$\\nabla \\eta(\\theta_{p})$ $\\approx$ $ \\frac{1}{T}\\sum_{t=1}^{T}G_{t}\\nabla_{\\theta_{p}}log\\pi(a|s,\\theta_{p})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- G is constance \n",
    "\n",
    "$\\nabla \\eta(\\theta_{p})$ $\\approx$ $ \\frac{1}{T}\\sum_{t=1}^{T}\\nabla_{\\theta_{p}}G_{t}log\\pi(a|s,\\theta_{p})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla \\eta(\\theta_{p})$ $\\approx$ $ \\frac{1}{T}\\nabla_{\\theta_{p}}\\sum_{t=1}^{T}G_{t}log\\pi(a|s,\\theta_{p})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- minimize, 1/T is meaningless\n",
    "\n",
    "$\\nabla \\eta(\\theta_{p})$ $\\approx$ $ -\\sum_{t=1}^{T}G_{t}log\\pi(a|s,\\theta_{p})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{P,t+1} = \\theta_{P,t}+\\alpha G_{t}\\frac{\\nabla \\pi(a_{t}|s_{t})}{\\pi(a_{t}|s_{t})}$  \n",
    "$\\theta_{P,t+1} = \\theta_{P,t}+\\alpha G_{t}\\nabla log\\pi(a_{t}|s_{t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- V(s)\n",
    "- V(s) is baseline  \n",
    "\n",
    "maximize: $\\sum_{t=1}^{T}(G_{t}-V(s_{t})log\\pi(a_{t}|s_{t},\\theta_{p})$  \n",
    "\n",
    "- G- V(s) is advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta_{V,t+1} = \\theta_{V,t}+\\alpha (G_{t}-V_{t})\\nabla V_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with TD \n",
    "\n",
    "- can this be converted to a TD method? yes\n",
    "- called actor-critic method\n",
    "- policy is actor\n",
    "- value critic\n",
    "\n",
    "$\\theta_{P,t+1} = \\theta_{P,t}+\\alpha (r_{t+1}+\\gamma V(s_{t+1}) - V(s_{t}))\\nabla log\\pi(a_{t}|s_{t})$  \n",
    "$\\theta_{V,t+1} = \\theta_{V,t}+\\alpha (r_{t+1}+\\gamma V(s_{t+1})-V(s_{t}))\\nabla V_{t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def main():\n",
    "  env = gym.make('MountainCarContinuous-v0')\n",
    "  ft = FeatureTransformer(env, n_components=100)\n",
    "  D = ft.dimensions\n",
    "  pmodel = PolicyModel(D, ft, [])\n",
    "  vmodel = ValueModel(D, ft, [])\n",
    "  init = tf.global_variables_initializer()\n",
    "  session = tf.InteractiveSession()\n",
    "  session.run(init)\n",
    "  pmodel.set_session(session)\n",
    "  vmodel.set_session(session)\n",
    "  gamma = 0.95\n",
    "\n",
    "  N = 50\n",
    "  totalrewards = np.empty(N)\n",
    "  costs = np.empty(N)\n",
    "  for n in range(N):\n",
    "    totalreward, num_steps = play_one_td(env, pmodel, vmodel, gamma)\n",
    "    totalrewards[n] = totalreward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous , Discrete Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Continuous \n",
    "- 'Gaussian distribution : mean and variance'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Gradient Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Continuous Actions   \n",
    "\n",
    "```python\n",
    "\n",
    "# approximates pi(a | s)\n",
    "class PolicyModel:\n",
    "  def __init__(self, ft, D, hidden_layer_sizes_mean=[], hidden_layer_sizes_var=[]):\n",
    "  'D is state dimension, latent vector size'\n",
    "  \n",
    "  # mean final layer\n",
    "  ...\n",
    "  M1 = D\n",
    "  layer = HiddenLayer(M1, 1, lambda x: x, use_bias=False, zeros=True)\n",
    "  self.mean_layers.append(layer)\n",
    "  ...\n",
    "  ##### model the variance #####\n",
    "  self.var_layers = []\n",
    "  'activation function is softplus'\n",
    "  # variance final layer\n",
    "  ...\n",
    "  layer = HiddenLayer(M1, 1, tf.nn.softplus, use_bias=False, zeros=False)\n",
    "  self.var_layers.append(layer)\n",
    "  \n",
    "  # gather params\n",
    "  self.params = []\n",
    "  for layer in (self.mean_layers + self.var_layers):\n",
    "    self.params += layer.params\n",
    "    \n",
    "  # inputs and targets\n",
    "  self.X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "  'predicted action from PolicyModel : self.predict_op'\n",
    "  self.actions = tf.placeholder(tf.float32, shape=(None,), name='actions')\n",
    "  self.advantages = tf.placeholder(tf.float32, shape=(None,), name='advantages')\n",
    "  \n",
    "  # calculate output and cost\n",
    "  mean = get_output(self.mean_layers)\n",
    "  std = get_output(self.var_layers) + 1e-4 # smoothing\n",
    "\n",
    "  # note: the 'variance' is actually standard deviation\n",
    "  norm = tf.contrib.distributions.Normal(mean, std)\n",
    "  self.predict_op = tf.clip_by_value(norm.sample(), -1, 1)\n",
    "\n",
    "  log_probs = norm.log_prob(self.actions)\n",
    "  cost = -tf.reduce_sum(self.advantages * log_probs + 0.1*norm.entropy())\n",
    "  self.train_op = tf.train.AdamOptimizer(1e-3).minimize(cost)  \n",
    "  \n",
    "```\n",
    "$$ \\bbox[yellow]\n",
    "{\n",
    "\\nabla \\eta(\\theta_{p}) \\approx  -\\sum_{t=1}^{T}G_{t}log\\pi(a|s,\\theta_{p}) \\\\\n",
    "\\theta_{P,t+1} = \\theta_{P,t}+\\alpha G_{t}\\frac{\\nabla \\pi(a_{t}|s_{t})}{\\pi(a_{t}|s_{t})}  \\\\\n",
    "\\theta_{P,t+1} = \\theta_{P,t}+\\alpha G_{t}\\nabla log\\pi(a_{t}|s_{t}) \\\\\n",
    "}\n",
    "$$\n",
    "\n",
    "```python\n",
    "'update weights '\n",
    "def partial_fit(self, X, actions, advantages):\n",
    "    X = np.atleast_2d(X)\n",
    "    X = self.ft.transform(X)\n",
    "    \n",
    "    actions = np.atleast_1d(actions)\n",
    "    advantages = np.atleast_1d(advantages)\n",
    "    self.session.run(\n",
    "      self.train_op,\n",
    "      feed_dict={\n",
    "        self.X: X,\n",
    "        self.actions: actions,\n",
    "        self.advantages: advantages,\n",
    "      }\n",
    "    )\n",
    "```    \n",
    "\n",
    "```python\n",
    "# approximates V(s)\n",
    "class ValueModel:\n",
    "  def __init__(self, D, ft, hidden_layer_sizes=[]):\n",
    "    self.ft = ft\n",
    "    self.costs = []\n",
    "\n",
    "    # create the graph\n",
    "    self.layers = []\n",
    "    M1 = D\n",
    "    for M2 in hidden_layer_sizes:\n",
    "      layer = HiddenLayer(M1, M2)\n",
    "      self.layers.append(layer)\n",
    "      M1 = M2\n",
    "\n",
    "    # final layer\n",
    "    layer = HiddenLayer(M1, 1, lambda x: x)\n",
    "    self.layers.append(layer)\n",
    "\n",
    "    # inputs and targets\n",
    "    self.X = tf.placeholder(tf.float32, shape=(None, D), name='X')\n",
    "    self.Y = tf.placeholder(tf.float32, shape=(None,), name='Y')\n",
    "\n",
    "    # calculate output and cost\n",
    "    Z = self.X\n",
    "    for layer in self.layers:\n",
    "      Z = layer.forward(Z)\n",
    "    Y_hat = tf.reshape(Z, [-1]) # the output\n",
    "    self.predict_op = Y_hat\n",
    "\n",
    "    cost = tf.reduce_sum(tf.square(self.Y - Y_hat))\n",
    "    self.cost = cost\n",
    "    self.train_op = tf.train.AdamOptimizer(1e-1).minimize(cost)\n",
    "```    \n",
    "\n",
    "$$ \\bbox[yellow]\n",
    "{\n",
    "maximize: \\sum_{t=1}^{T}(G_{t}-V(s_{t})log\\pi(a_{t}|s_{t},\\theta_{p})  \\\\\n",
    "\\theta_{V,t+1} = \\theta_{V,t}+\\alpha (G_{t}-V_{t})\\nabla V_{t}\n",
    "}\n",
    "$$\n",
    "\n",
    "```python\n",
    "V_next = vmodel.predict(observation)\n",
    "G = reward + gamma*V_next\n",
    "advantage = G - vmodel.predict(prev_observation)\n",
    "pmodel.partial_fit(prev_observation, action, advantage)\n",
    "vmodel.partial_fit(prev_observation, G)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Discrete Actions\n",
    "\n",
    "```python\n",
    "# approximates pi(a | s)\n",
    "class PolicyModel:\n",
    "  def __init__(self, D, K, hidden_layer_sizes):\n",
    "    \"p_a_given_s is final layer's output \"\n",
    "    self.predict_op = p_a_given_s\n",
    "\n",
    "    '# K = number of actions'\n",
    "    # self.one_hot_actions = tf.one_hot(self.actions, K)\n",
    "    selected_probs = tf.log(\n",
    "      tf.reduce_sum(\n",
    "        p_a_given_s * tf.one_hot(self.actions, K),\n",
    "        reduction_indices=[1]\n",
    "      )\n",
    "    )\n",
    "\n",
    "    # self.selected_probs = selected_probs\n",
    "    cost = -tf.reduce_sum(self.advantages * selected_probs)\n",
    "    self.train_op = tf.train.AdagradOptimizer(1e-1).minimize(cost)\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PG Summary\n",
    "\n",
    "- Discrete Actions: softmax\n",
    "- Continuous Actions: Gaussian or any other continuous distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta = \\theta + \\alpha(r+ \\gamma max_{a'}Q'(s',a') - Q(s,a))\\nabla_{\\theta}Q(s,a)$  \n",
    "\n",
    "- x = feature_expansion(s)\n",
    "- each output node corresponds to a difference action a\n",
    "- `Experience Memory(replay buffer)` : correlation removed\n",
    "- sample a random batch from the buffer, do gradient descent\n",
    "- buffer is a queue:FIFO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `DQN, dual network, target network`\n",
    "- to remove instability of deep Q network because Q'(s',a') is approximation network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Dealing with Images`\n",
    "- state(t) = [image(t-3),image(t-2),image(t-1),image(t)]\n",
    "- stack 4 frames: (4, H,W,C)\n",
    "- convert to grayscale: (4, H,W)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN code\n",
    "\n",
    "- `cost function`\n",
    "```python\n",
    "class DQN:\n",
    "    self.predict_op = Y_hat\n",
    "\n",
    "    selected_action_values = tf.reduce_sum(\n",
    "      Y_hat * tf.one_hot(self.actions, K),\n",
    "      reduction_indices=[1]\n",
    "    )\n",
    "\n",
    "    cost = tf.reduce_sum(tf.square(self.G - selected_action_values))\n",
    "    self.train_op = tf.train.AdamOptimizer(1e-2).minimize(cost)\n",
    "```\n",
    "$$ \\bbox[yellow]\n",
    "{\n",
    "G = r+ \\gamma max_{a'}Q'(s',a')\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train`\n",
    "\n",
    "```python\n",
    "while not done and iters < 2000:\n",
    "    # if we reach 2000, just quit, don't want this going forever\n",
    "    # the 200 limit seems a bit early\n",
    "    action = model.sample_action(observation, eps)\n",
    "    prev_observation = observation\n",
    "    observation, reward, done, info = env.step(action)\n",
    "\n",
    "    totalreward += reward\n",
    "    if done:\n",
    "      reward = -200\n",
    "\n",
    "    # update the model\n",
    "    \"add s,a,s',r into replay buffer\"\n",
    "    model.add_experience(prev_observation, action, reward, observation, done)\n",
    "    \"targets = [r + self.gamma*next_q if not done else r for r, next_q, done in zip(rewards, next_Q, dones)]\"\n",
    "    \"calculate G,and run train_op\"\n",
    "    model.train(tmodel)\n",
    "\n",
    "    iters += 1\n",
    "\n",
    "    if iters % copy_period == 0:\n",
    "      tmodel.copy_from(model)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A3C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Asynchronous Advantage Actor - Critic`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Actor : Policy\n",
    "- Critic : Value\n",
    "- Advantage : G- V(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Gradient Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "\\pi(a|s,\\theta_p) = NeuralNet(input:s,weight:\\theta_p)\\\\\n",
    "V(a|s,\\theta_v) = NeuralNet(input:s,weight:\\theta_v)\n",
    "\\end{equation*}\n",
    "\n",
    "- For policy loss, backwards from policy gradient, For Value loss, use squared error\n",
    "\\begin{equation*}\n",
    "L_p = -(G- V(s))log\\pi(a|s,\\theta_p)\\\\\n",
    "L_v = (G-V(s,\\theta_v))^2\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pseudocode\n",
    "\\begin{equation*}\n",
    "\\theta_p = \\theta_p - learningrate* dL_p/d\\theta_p \\\\\n",
    "\\theta_v = \\theta_v - learningrate* dL_v/d\\theta_v\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- N-Step return \n",
    "- instead of using TD(0), we use the N-step return\n",
    "\\begin{equation*}\n",
    "V(s)= r + \\gamma r' + \\gamma^2 r'' + \\gamma^3 V(s''')\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Entropy Regularization\n",
    "- Definition of entropy\n",
    "\\begin{equation*}\n",
    "H = - \\sum_{k=1}^n \\pi_k log\\pi_k\n",
    "\\end{equation*}\n",
    "\n",
    "- New loss (C: regularization constant)\n",
    "\\begin{equation*}\n",
    "L_p'= L_p +CH\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cn.bing.com/th?id=OIP.TlKyrDc2rVlD0tNkkderjAHaGs&pid=Api&rs=1&p=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A3C simply achieves stability using a different method(parallel agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Global network` has no work to do- the workers do all the work\n",
    "- `Workers` paly episodes, calculate errors and gradient updates\n",
    "- The global network gets many updates in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- multiple parallel agents and asynchronously update/copy parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "1. create workers\n",
    "2. copy weights from global nets\n",
    "3. play episodes\n",
    "4. send gradients back to master\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- global network\n",
    "\n",
    "\n",
    "$g_{local} =  \\frac{\\partial L(\\theta_{local})}{\\partial \\theta_{local}}$  \n",
    "$\\theta_{global} =  \\theta_{global}+ \\eta g_{local}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create Worker Threads`\n",
    "\n",
    "```python\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  coord = tf.train.Coordinator()\n",
    "\n",
    "  # Start worker threads\n",
    "  worker_threads = []\n",
    "  for worker in workers:\n",
    "    worker_fn = lambda: worker.run(sess, coord, STEPS_PER_UPDATE)\n",
    "    t = threading.Thread(target=worker_fn)\n",
    "    t.start()\n",
    "    worker_threads.append(t)\n",
    "\n",
    "  # Wait for all workers to finish\n",
    "  coord.join(worker_threads, stop_grace_period_secs=300)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Class Worker `\n",
    "\n",
    "```python\n",
    "class Worker:\n",
    "    self.policy_net, self.value_net = create_networks(policy_net.num_outputs)\n",
    "    \n",
    "    def run():\n",
    "        # Collect some experience\n",
    "        steps, global_step = self.run_n_steps(t_max, sess)\n",
    "        ...\n",
    "        # Update the global networks using local gradients\n",
    "        self.update(steps, sess)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Update gradients`\n",
    "\n",
    "```python\n",
    "def update(self, steps, sess):\n",
    "    \"\"\"\n",
    "    Updates global policy and value networks using the local networks' gradients\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    # [[local_g1, local_g2, local_g3], [global_v1, global_v2, global_v3]]\n",
    "    # First get only the gradients\n",
    "    local_grads, _ = zip(*local_net.grads_and_vars)\n",
    "\n",
    "    # Clip gradients to avoid large values\n",
    "    local_grads, _ = tf.clip_by_global_norm(local_grads, 5.0)\n",
    "\n",
    "    # Get global vars\n",
    "    _, global_vars = zip(*global_net.grads_and_vars)\n",
    "\n",
    "    # Combine local grads and global vars\n",
    "    local_grads_global_vars = list(zip(local_grads, global_vars))\n",
    "\n",
    "    # Run a gradient descent step, e.g.\n",
    "    # var = var - learning_rate * grad\n",
    "    global_net.optimizer.apply_gradients(\n",
    "    local_grads_global_vars,\n",
    "    global_step=tf.train.get_global_step())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\bbox[yellow]\n",
    "{\n",
    "g_{local} =  \\frac{\\partial L(\\theta_{local})}{\\partial \\theta_{local}}   \\\\\n",
    "\\theta_{global} =  \\theta_{global}+ \\eta g_{local}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Loss function`\n",
    "\n",
    "```python\n",
    "class PolicyNetwork:\n",
    "    ...\n",
    "    self.probs = tf.nn.softmax(self.logits)\n",
    "    # Add regularization to increase exploration\n",
    "    self.entropy = -tf.reduce_sum(self.probs * tf.log(self.probs), axis=1)\n",
    "    \n",
    "    ...\n",
    "    self.loss = tf.log(self.selected_action_probs) * self.advantage + reg * self.entropy\n",
    "    self.loss = -tf.reduce_sum(self.loss, name=\"loss\")\n",
    "\n",
    "    # training\n",
    "    self.optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6)\n",
    "\n",
    "    # we'll need these later for running gradient descent steps\n",
    "    self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "    self.grads_and_vars = [[grad, var] for grad, var in self.grads_and_vars if grad is not None]\n",
    "\n",
    "class ValueNetwork:\n",
    "    ...\n",
    "    self.loss = tf.squared_difference(self.vhat, self.targets)\n",
    "    self.loss = tf.reduce_sum(self.loss, name=\"loss\")\n",
    "\n",
    "    # training\n",
    "    self.optimizer = tf.train.RMSPropOptimizer(0.00025, 0.99, 0.0, 1e-6)\n",
    "\n",
    "    # we'll need these later for running gradient descent steps\n",
    "    self.grads_and_vars = self.optimizer.compute_gradients(self.loss)\n",
    "    self.grads_and_vars = [[grad, var] for grad, var in self.grads_and_vars if grad is not None]\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
